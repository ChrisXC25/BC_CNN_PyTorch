#create training and testing set

# two ways (sklearn and PyTorch random_split, we will use random_split here)

import torch 
from torchvision import datasets, transforms
from torch.utils.data import random_split, DataLoader

# data transformation format 

transforms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                         std=[0.229, 0.224, 0.225])
])

image_dataset = datasets.ImageFolder(
    root='/content/breast_cancer_data_sorted',
    transform=transforms
)
# show number of images and class labels 
print('Number of images: ', len(image_dataset))
print('Class labels: ', image_dataset.classes)

# total num of images: 277524

# create training and testing set 

train_set, test_set = random_split(image_dataset, [0.7, 0.3], 
                generator=torch.Generator().manual_seed(25))

print(f'Training set size: {len(train_set)},Testing set size:{len(test_set)}')

# training size: 194267
# testing size : 83257

train_loader = DataLoader(train_set, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_set, batch_size = 32, shuffle=False)

#######################################

# construct a simple CNN model 

import torch 
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

class BC_CNN_classifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),  
            nn.ReLU(),
            nn.MaxPool2d(2),                            

            nn.Conv2d(16, 32, kernel_size=3, padding=1), 
            nn.ReLU(),
            nn.MaxPool2d(2),                            
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(32 * 56 * 56, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 2)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

#################################

# set gpu usage

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

# set hyperparameters 

model = BC_CNN_classifier().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

print(train_loader)
print(test_loader)

###################################
# training loops

# we will train the model for 10 epochs 

num_epochs = 10 

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        predicted_labels = model(images)
        loss = criterion(predicted_labels, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
    avg_loss = running_loss / len(train_loader)

    print(f"Epoch [{epoch+1}/{num_epochs}], loss: {avg_loss: .5f}")
    
    
# save the BC_CNN model

torch.save(model.state_dict(), '/content/BC_CNN_model.pth')

# for model loading 

#model = BC_CNN_classifier().to(device)
#model.load_state_dict(torch.load('BC_CNN_model.pth'))

m1 = model.state_dict()
m1_hyper = optimizer.state_dict()
print(m1.keys())
print(m1_hyper.keys())
print(model.eval())

#####################################

# model eval for accuracy 

correct = 0 
total = 0 

with torch.no_grad():
  for images, labels in test_loader: 
    images, labels = images.to(device), labels.to(device)
    predicted = model(images)
    _, predicted_outputs = torch.max(predicted, 1)
    total += labels.size(0)
    correct += (predicted_outputs == labels).sum().item()

accuracy = correct/total

print(f'Test_accuracy of BC_CNN : {accuracy: .2f}%')

# test accuracy 0.85 with 10 epochs trained 

# import sklearn packages 

from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score, roc_curve
from sklearn.metrics import precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np 

# get all predictions and groud truth labels

all_preds = []
all_probs = []
all_labels = []

model.eval()

with torch.no_grad():
  for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    out_logits = model(images)
    probability = torch.softmax(out_logits, dim=1)[:,1]
    _, predicted = torch.max(out_logits, 1)

# make the predictions, probability and labels as flatten list 

    all_preds.extend(predicted.cpu().numpy())
    all_probs.extend(probability.cpu().numpy())
    all_labels.extend(labels.cpu().numpy())

print("Predicted classes (all_preds):", all_preds[:5])
print("Predicted probabilities (all_probs):", all_probs[:5])
print("True labels (all_labels):", all_labels[:5])

# get confusion matrix 

cm = confusion_matrix(all_labels, all_preds)
print(cm)
class_names = ['IDC Negative (0)', 'IDC Positive (1)']
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix for BC_CNN Classifier')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.tight_layout()
plt.show()

# precision, recall and f1

precision = precision_score(all_labels, all_preds)
recall = recall_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds)

print(f'percision:{precision:.2f}')
print(f'recall:{recall:.2f}')
print(f'f1:{f1:.2f}')


auc = roc_auc_score(all_labels, all_probs)
print(f'auc score: {auc:.2f}')

fpr, tpr, _ = roc_curve(all_labels, all_probs)
plt.plot(fpr, tpr, label = f'auc score: {auc:.2f}')
plt.xlabel('false positive rate')
plt.ylabel('true positive rate')
plt.title('ROC curve') # auc: 0.88
